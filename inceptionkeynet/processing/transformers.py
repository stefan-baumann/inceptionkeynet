from __future__ import annotations # Enable postponed evaluation of annotations to allow for annotating methods returning their enclosing type

from typing import Dict, Any, Optional, Tuple
import logging
import math

import numpy as np
from scipy import signal
from scipy import interpolate
import librosa
import sox
import pyfftw
import pyrubberband

import inceptionkeynet
from inceptionkeynet.processing import Transformer, TransformerChain, Transformers




class AbsoluteConstantQTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, samplerate: Optional[int] = None, note_min: str = 'C1', note_max: str = 'C8', bins_per_semitone: int = 2, res_type: str = None):
        self.samplerate = samplerate if not samplerate is None else inceptionkeynet.AUDIO_SAMPLE_RATE
        self.note_min = note_min
        self.note_max = note_max
        self.bins_per_semitone = bins_per_semitone
        self.res_type = res_type
        
        super().__init__(f'abs_cqt-({self.samplerate}-{self.note_min}-to-{self.note_max}-bps-{self.bins_per_semitone})')

    def transform(self, input: np.ndarray) -> np.ndarray:
        """input is expected to be a mono channel of samples."""
        if not len(input.shape) == 1:
            raise ValueError(f'Expected input data with a dimensionality of 1, got {len(input.shape)} (exact shape was {repr(input.shape)}).')
        
        n_bins = (librosa.note_to_midi(self.note_max) - librosa.note_to_midi(self.note_min)) * self.bins_per_semitone
        return np.abs(librosa.cqt(input, sr=self.samplerate, fmin=librosa.note_to_hz(self.note_min), n_bins=n_bins, bins_per_octave=(12 * self.bins_per_semitone), res_type=self.res_type))

    def to_dict(self):
        return {
            'samplerate': self.samplerate,
            'note_min': self.note_min,
            'note_max': self.note_max,
            'bins_per_semitone': self.bins_per_semitone,
            'res_type': self.res_type
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return AbsoluteConstantQTransformer(dict['samplerate'], dict['note_min'], dict['note_max'], dict['bins_per_semitone'], dict['res_type'] if 'res_type' in dict else None)
    
# Register transformer
Transformers['abs_cqt'] = AbsoluteConstantQTransformer



class PitchShiftTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, samplerate: Optional[int] = None, shift_semitones: int = 0, use_sox: bool = True):
        self.samplerate = samplerate if not samplerate is None else inceptionkeynet.AUDIO_SAMPLE_RATE
        self.shift_semitones = shift_semitones
        self.use_sox = use_sox
        if self.use_sox:
            self.sox_tfm = sox.Transformer()
            self.sox_tfm.pitch(self.shift_semitones)
        
        super().__init__(f'pitch_shift-({self.samplerate}-{self.shift_semitones}{"-sox" if self.use_sox else ""})', save_as_audio=True)

    def transform(self, input: np.ndarray) -> np.ndarray:
        """input is expected to be a mono channel of samples."""
        if not len(input.shape) == 1:
            raise ValueError(f'Expected input data with a dimensionality of 1, got {len(input.shape)} (exact shape was {repr(input.shape)}).')
        
        if self.use_sox:
            return self.sox_tfm.build_array(input_array=input, sample_rate_in=self.samplerate)
        else:
            return pyrubberband.pyrb.pitch_shift(input, self.samplerate, self.shift_semitones)

    def to_dict(self):
        return {
            'samplerate': self.samplerate,
            'shift_semitones': self.shift_semitones,
            # 'bins_per_semitone': self.bins_per_semitone,
            'use_sox': self.use_sox
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return PitchShiftTransformer(dict['samplerate'], dict['shift_semitones'], use_sox=(dict['use_sox'] if 'use_sox' in dict else False))
    
# Register transformer
Transformers['pitch_shift'] = PitchShiftTransformer



class SpectrogramTimeDownsamplingTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, downsampling_factor: float = 1):
        self.downsampling_factor = downsampling_factor
        super().__init__(f'spectrogram_time_downsampling_{downsampling_factor}')

    def transform(self, input: np.ndarray) -> np.ndarray:
        """Input is expected to be a spectrogram (e.g. generated by SciPyAbsoluteSTFTTransformer or AbsoluteConstantQTransformer) with two dimensions where time is the last."""
        if len(input.shape) == 2:
            bins, times = input.shape
            times_downsampled = max(1, int(times / self.downsampling_factor))
            xrange = lambda x: np.linspace(0, 1, x)
            return interpolate.interp2d(xrange(times), xrange(bins), input, kind='linear')(xrange(times_downsampled), xrange(bins))
        else:
            raise ValueError(f'Expected input data with a dimensionality of 2, got {len(input.shape)} (exact shape was {repr(input.shape)}).')

    def to_dict(self):
        return { 'downsampling_factor': self.downsampling_factor }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return SpectrogramTimeDownsamplingTransformer(dict['downsampling_factor'])
    
# Register transformer
Transformers['spectrogram_time_downsampling'] = SpectrogramTimeDownsamplingTransformer



class LoudnessTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, f: float = 1):
        super().__init__(f'loudness_{f}')
        self.f = f

    def transform(self, input: np.ndarray) -> np.ndarray:
        return input * self.f

    def to_dict(self):
        return {
            'f': self.f
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return LoudnessTransformer(dict['f'])
    
# Register transformer
Transformers['loudness'] = LoudnessTransformer



class LoudnessAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, f_max: float = 1):
        super().__init__(f'loudness_augmentation_{f_max}')
        self.f_max = f_max

    def transform(self, input: np.ndarray) -> np.ndarray:
        f = np.random.uniform(1 / self.f_max, self.f_max)
        return input * f

    def to_dict(self):
        return {
            'f_max': self.f_max
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return LoudnessAugmentationTransformer(dict['f_max'])
    
# Register transformer
Transformers['loudness_augmentation'] = LoudnessAugmentationTransformer



class AdditiveGaussianNoiseTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, mean: float = 0, sigma: float = 0):
        super().__init__(f'additive_gaussian_noise_{mean}_{sigma}')
        self.mean = mean
        self.sigma = sigma

    def transform(self, input: np.ndarray) -> np.ndarray:
        noise_matrix = np.random.normal(self.mean, self.sigma, input.shape)
        return input + noise_matrix

    def to_dict(self):
        return {
            'mean': self.mean,
            'sigma': self.sigma
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return AdditiveGaussianNoiseTransformer(dict['mean'], dict['sigma'])
    
# Register transformer
Transformers['additive_gaussian_noise'] = AdditiveGaussianNoiseTransformer



class AdditiveGaussianNoiseAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, mean: float = 0, sigma_max: float = 0):
        super().__init__(f'additive_gaussian_noise_augmentation_{mean}_{sigma_max}')
        self.mean = mean
        self.sigma_max = sigma_max

    def transform(self, input: np.ndarray) -> np.ndarray:
        sigma = np.random.uniform(0, self.sigma_max)
        noise_matrix = np.random.normal(self.mean, sigma, input.shape)
        return input + noise_matrix

    def to_dict(self):
        return {
            'mean': self.mean,
            'sigma_max': self.sigma_max
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return AdditiveGaussianNoiseAugmentationTransformer(dict['mean'], dict['sigma_max'])
    
# Register transformer
Transformers['additive_gaussian_noise_augmentation'] = AdditiveGaussianNoiseAugmentationTransformer




class TimeLogFrequencyDomainBellCurveEQTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, i_center: int = 0, sigma: float = 0, s: float = 0):
        super().__init__(f't_f_bell_curve_{i_center}_{sigma}_{s}')
        self.i_center = i_center
        self.sigma = sigma
        self.s = s

    def transform(self, input: np.ndarray) -> np.ndarray:
        filter = np.array([self.s * math.exp(-.5 * math.pow(i - self.i_center, 2) / math.pow(self.sigma, 2)) / (self.sigma * math.sqrt(2 * math.pi)) for i in range(0, input.shape[0])])
        return np.maximum(input * (1 + filter[:,np.newaxis]), 0)

    def to_dict(self):
        return {
            'i_center': self.i_center,
            'sigma': self.sigma,
            's': self.s
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeLogFrequencyDomainBellCurveEQTransformer(dict['i_center'], dict['sigma'], dict['s'])
    
# Register transformer
Transformers['t_f_bell_curve'] = TimeLogFrequencyDomainBellCurveEQTransformer



class TimeLogFrequencyDomainBellCurveEQAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, i_center_range: Tuple[int, int] = (0, 0), sigma_max: float = 0, s_max: float = 0):
        super().__init__(f't_f_bell_curve_augmentation_{i_center_range[0]}_{i_center_range[1]}_{sigma_max}_{s_max}')
        self.i_center_range = i_center_range
        self.sigma_max = sigma_max
        self.s_max = s_max

    def transform(self, input: np.ndarray) -> np.ndarray:
        i_center = int(np.random.uniform(self.i_center_range[0], self.i_center_range[1] if not self.i_center_range[1] < 0 else input.shape[0] - self.i_center_range[1]))
        sigma = np.random.uniform(0, self.sigma_max)
        s = np.random.uniform(-self.s_max, self.s_max)
        filter = np.array([s * math.exp(-.5 * math.pow(i - i_center, 2) / math.pow(sigma, 2)) / (sigma * math.sqrt(2 * math.pi)) for i in range(0, input.shape[0])])
        return np.maximum(input * (1 + filter[:,np.newaxis]), 0)

    def to_dict(self):
        return {
            'i_center_range': self.i_center_range,
            'sigma_max': self.sigma_max,
            's_max': self.s_max
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeLogFrequencyDomainBellCurveEQAugmentationTransformer(tuple(dict['i_center_range']), dict['sigma_max'], dict['s_max'])
    
# Register transformer
Transformers['t_f_bell_curve_augmentation'] = TimeLogFrequencyDomainBellCurveEQAugmentationTransformer



class TimeFrequencyDomainTimeWarpTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, warp_distance: float = 0):
        super().__init__(f't_f_time_warp_{warp_distance}')
        self.warp_distance = warp_distance

    def transform(self, input: np.ndarray) -> np.ndarray:
        bins, times = input.shape
        xrange = lambda x: np.linspace(0, 1, x)
        x_1 = times // 2 + self.warp_distance
        x_2 = times - x_1
        xwarprange = np.concatenate((np.linspace(0, .5, x_1, endpoint=False), np.linspace(.5, 1, x_2)))
        return interpolate.interp2d(xrange(times), xrange(bins), input, kind='linear')(xwarprange, xrange(bins))

    def to_dict(self):
        return {
            'warp_distance': self.warp_distance
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeFrequencyDomainTimeWarpTransformer(dict['warp_distance'])
    
# Register transformer
Transformers['t_f_time_warp'] = TimeFrequencyDomainTimeWarpTransformer



class TimeFrequencyDomainTimeWarpAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, max_warp_distance: float = 0):
        super().__init__(f't_f_time_warp_augmentation_{max_warp_distance}')
        self.max_warp_distance = max_warp_distance

    def transform(self, input: np.ndarray) -> np.ndarray:
        warp_distance = int(np.random.uniform(-self.max_warp_distance, self.max_warp_distance))
        bins, times = input.shape
        xrange = lambda x: np.linspace(0, 1, x)
        x_1 = times // 2 + warp_distance
        x_2 = times - x_1
        xwarprange = np.concatenate((np.linspace(0, .5, x_1, endpoint=False), np.linspace(.5, 1, x_2)))
        return interpolate.interp2d(xrange(times), xrange(bins), input, kind='linear')(xwarprange, xrange(bins))

    def to_dict(self):
        return {
            'max_warp_distance': self.max_warp_distance
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeFrequencyDomainTimeWarpAugmentationTransformer(dict['max_warp_distance'])
    
# Register transformer
Transformers['t_f_time_warp_augmentation'] = TimeFrequencyDomainTimeWarpAugmentationTransformer



class TimeMaskingTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, t_0: float, t: float):
        super().__init__(f'time_mask_{t_0}_{t}')
        self.t_0 = t_0
        self.t = t

    def transform(self, input: np.ndarray) -> np.ndarray:
        input[:,self.t_0:(self.t_0+self.t)] = 0
        return input

    def to_dict(self):
        return {
            't_0': self.t_0,
            't': self.t
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeMaskingTransformer(dict['t_0'], dict['t'])
    
# Register transformer
Transformers['time_mask'] = TimeMaskingTransformer



class TimeMaskingAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, max_t: float):
        super().__init__(f'time_mask_augmentation_{max_t}')
        self.max_t = max_t

    def transform(self, input: np.ndarray) -> np.ndarray:
        t = int(np.random.uniform(0, self.max_t))
        t_0 = int(np.random.uniform(0, input.shape[1] - t - 1))
        input[:,t_0:(t_0+t)] = 0
        return input

    def to_dict(self):
        return {
            'max_t': self.max_t,
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return TimeMaskingAugmentationTransformer(dict['max_t'])
    
# Register transformer
Transformers['time_mask_augmentation'] = TimeMaskingAugmentationTransformer



class FrequencyMaskingTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, f_0: float, f: float):
        super().__init__(f'frequency_mask_{f_0}_{f}')
        self.f_0 = f_0
        self.f = f

    def transform(self, input: np.ndarray) -> np.ndarray:
        input[self.f_0:(self.f_0+self.f)] = 0
        return input

    def to_dict(self):
        return {
            'f_0': self.f_0,
            'f': self.f
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return FrequencyMaskingTransformer(dict['f_0'], dict['f'])
    
# Register transformer
Transformers['frequency_mask'] = FrequencyMaskingTransformer



class FrequencyMaskingAugmentationTransformer(Transformer[np.ndarray, np.ndarray]):
    def __init__(self, max_f: float):
        super().__init__(f'frequency_mask_augmentation_{max_f}')
        self.max_f = max_f

    def transform(self, input: np.ndarray) -> np.ndarray:
        f = int(np.random.uniform(0, self.max_f))
        f_0 = int(np.random.uniform(0, input.shape[0] - f - 1))
        input[f_0:(f_0+f)] = 0
        return input

    def to_dict(self):
        return {
            'max_f': self.max_f,
        }

    @classmethod
    def from_dict(cls, dict: Dict[str, Any]) -> TransformerChain:
        return FrequencyMaskingAugmentationTransformer(dict['max_f'])
    
# Register transformer
Transformers['frequency_mask_augmentation'] = FrequencyMaskingAugmentationTransformer